{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fb422d-6fb0-4159-b6e5-79bff41dc79b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bipedal_Walker\n",
    "## Deep Deterministic Policy Gradient (DDPG) TD3 variant\n",
    "https://pylessons.com/BipedalWalker-v3-PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28409768-9bc1-44c3-82ed-0ca9e0b7f251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import os\n",
    "import base64\n",
    "import random\n",
    "import time\n",
    "\n",
    "# import third-party libraries\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc43622-7836-473b-914d-6c143a7c5cb7",
   "metadata": {},
   "source": [
    "## Hardware infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fd67c7-c94a-49c2-90f7-e3ed1ea56ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a786ed-9ed2-4f0b-ad4e-f1f22b4c0b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 17:23:23.477657: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-06-18 17:23:23.477694: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-06-18 17:23:23.477707: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-06-18 17:23:23.477772: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-18 17:23:23.477802: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_logical_devices())\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "print(len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6bb6b3-9668-4f96-8621-261c2c8d60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc77739d-780d-44dc-ad01-be2ae4aa1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f09ad1-ce47-4c44-a91a-e7f6a082fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0-rc1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356b2e08-ac0c-4a0c-a12e-4f6adaabc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232c832-cd45-432f-a602-4442a0105b43",
   "metadata": {},
   "source": [
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89dc8a76-424c-4823-afb3-b04e7a116279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./img :\n",
      "total 30808\n",
      "drwxr-xr-x   7 thibaudperrin  staff       224 18 jui 16:26 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  19 thibaudperrin  staff       608 18 jui 17:22 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--   1 thibaudperrin  staff    464369 18 jui 12:32 BipedalWalker-v3-w0-e0.gif\n",
      "-rw-r--r--   1 thibaudperrin  staff    889495 18 jui 16:26 Pendulum-v1.gif\n",
      "-rw-r--r--   1 thibaudperrin  staff   1480449 18 jui 12:32 bipedal_walker.gif\n",
      "-rw-r--r--   1 thibaudperrin  staff  12930388 18 jui 12:32 lunar_lander.gif\n",
      "drwxr-xr-x   2 thibaudperrin  staff        64 18 jui 15:11 \u001b[34mpendulum\u001b[m\u001b[m\n",
      "./data :\n",
      "total 0\n",
      "drwxr-xr-x   3 thibaudperrin  staff   96 18 jui 15:12 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  19 thibaudperrin  staff  608 18 jui 17:22 \u001b[34m..\u001b[m\u001b[m\n",
      "drwxr-xr-x   2 thibaudperrin  staff   64 18 jui 15:12 \u001b[34mpendulum\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('img/pendulum', exist_ok=True)\n",
    "os.makedirs('data/pendulum', exist_ok=True)\n",
    "print('./img :')\n",
    "!ls -al img\n",
    "print('./data :')\n",
    "!ls -al data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc8f7e-4ed4-4a9e-b222-f36d75a8efdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c447b469-f41b-48a4-98fd-bea9449be473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'Pendulum-v1'\n",
    "\n",
    "# Hyperparameters\n",
    "MEMORY_SIZE = 1_000_000 # 100_000     # size of memory buffer\n",
    "MINIBATCH_SIZE = 64                   # mini-batch size\n",
    "ACTOR_LR = 0.001                      # learning rate Actor model\n",
    "CRITIC_LR = 0.002 # 1e-4              # learning rate Critic model\n",
    "GAMMA = 0.99                          # discount factor\n",
    "TAU = 0.005                           # soft update parameter\n",
    "EPISODES = 100                        # Total number of episodes\n",
    "\n",
    "NOISE_MEAN = 0.0\n",
    "NOISE_STDDEV = 0.2\n",
    "NOISE_DECAY = 0.99                    # adjusts the magnitude of the noise over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245044f-92da-4454-8d20-9ec39e0c7251",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d56e4f-7c3f-4e17-98d2-c08b4554dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(value, max_value, visualize: bool = False) -> str:\n",
    "    percent = int(value*10/max_value)\n",
    "    progress = f\"{''.join(['█' if x < percent  else '░' for x in range(10)])} ({value}/{max_value})\"\n",
    "    if visualize:\n",
    "        print(progress)\n",
    "    return progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5742f352-c0c2-4f81-8da3-60dbf4b140c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_gif(img_list, path):\n",
    "    # Convert the list of frames to a numpy array\n",
    "    resized_img_array = []\n",
    "    for img in img_list:\n",
    "        img_pil = Image.fromarray(img)\n",
    "        # Make sure width and height are divisible by 16\n",
    "        img_resized_pil = img_pil.resize((608, 400))\n",
    "        img_resized = np.array(img_resized_pil)\n",
    "        resized_img_array.append(img_resized)\n",
    "    \n",
    "    # Create gif video\n",
    "    fps = 20\n",
    "    imageio.mimsave(path, resized_img_array, 'GIF', duration=int(1000 * 1/fps), loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe63630-0057-48a4-bee9-9ae6f63b02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_loss(critic, states, actions):\n",
    "    q_values = critic.model([states, actions])\n",
    "    return -tf.reduce_mean(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50842055-295e-42c7-a275-82e612e7569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_weights(model, target_model, tau=TAU):\n",
    "    weights = model.get_weights()\n",
    "    target_weights = target_model.get_weights()\n",
    "    for i in range(len(weights)):\n",
    "        target_weights[i] = weights[i] * tau + target_weights[i] * (1 - tau)\n",
    "    target_model.set_weights(target_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d99dba-020f-45ff-b92b-840d4e0308aa",
   "metadata": {},
   "source": [
    "## Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af47c26f-6c50-4682-a291-e67a957dc495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, state_dim, action_dim, action_bound, learning_rate=ACTOR_LR):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.action_bound = action_bound\n",
    "        self.model = self.create_model(learning_rate)\n",
    "\n",
    "    def create_model(self, learning_rate):\n",
    "        states = Input(shape=(self.state_dim,))\n",
    "        out = Dense(24, activation='relu')(states)\n",
    "        out = Dense(24, activation='relu')(out)\n",
    "        actions = Dense(self.action_dim, activation='tanh')(out)\n",
    "        model = Model(inputs=states, outputs=actions)\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692dbe42-8e6f-42a3-b20b-910a8b782b3e",
   "metadata": {},
   "source": [
    "## Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3811642a-56c8-4b3e-8ab6-46f6ecf77c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Critic:\n",
    "    def __init__(self, state_dim, action_dim, learning_rate=CRITIC_LR):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.model = self.create_model(learning_rate)\n",
    "\n",
    "    def create_model(self, learning_rate):\n",
    "        states = Input(shape=(self.state_dim,))\n",
    "        actions = Input(shape=(self.action_dim,))\n",
    "        out = Concatenate()([states, actions])\n",
    "        out = Dense(24, activation='relu')(out)\n",
    "        out = Dense(24, activation='relu')(out)\n",
    "        q_values = Dense(1)(out)\n",
    "        model = Model(inputs=[states, actions], outputs=q_values)\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422a2ee-c0da-4f82-842f-9943b11379c3",
   "metadata": {},
   "source": [
    "## ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df408a67-8479-42e1-be66-0c9eb8ee3df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "\n",
    "    def add_record(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) >= self.max_size:\n",
    "            self.buffer.pop(0)\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.choice(len(self.buffer), size=batch_size)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        states, actions, rewards, next_states, dones = map(np.asarray, zip(*batch))\n",
    "        return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96934108-c114-4224-8213-8d820eb22f7a",
   "metadata": {},
   "source": [
    "## Training\n",
    "### create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a04738-0674-4303-8699-add717f0f56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd708c-dc14-42fc-a013-ed57c61e377a",
   "metadata": {},
   "source": [
    "### Create actor, critic and their target networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc98a06-f635-4267-a343-aaf483c6cb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actor = Actor(state_dim, action_dim, action_bound, ACTOR_LR)\n",
    "target_actor = Actor(state_dim, action_dim, action_bound, ACTOR_LR)\n",
    "critic = Critic(state_dim, action_dim, CRITIC_LR)\n",
    "target_critic = Critic(state_dim, action_dim, CRITIC_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c1ba6-463d-4b4c-8368-d8614c74c9f7",
   "metadata": {},
   "source": [
    "### Create replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e971063-03f2-4467-9d13-0b18a91d58f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af682ff2-47e9-497e-beb4-a272c00d16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all episodes rewards\n",
    "total_rewards = []\n",
    "\n",
    "# Create Ornstein-Uhlenbeck noise\n",
    "ou_noise = np.random.normal(NOISE_MEAN, NOISE_STDDEV, size=action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac083c96-d480-4338-97b8-19a4f0bbe31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: ░░░░░░░░░░ (2/100)\n",
      "Timestep: ███████░░░ (141/200), Episode reward = -869.584845770507\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     41\u001b[0m     new_actions \u001b[38;5;241m=\u001b[39m actor\u001b[38;5;241m.\u001b[39mmodel(states)\n\u001b[0;32m---> 42\u001b[0m     actor_loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_actor_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m actor_grad \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(actor_loss, actor\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     44\u001b[0m actor\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(actor_grad, actor\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mget_actor_loss\u001b[0;34m(critic, states, actions)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_actor_loss\u001b[39m(critic, states, actions):\n\u001b[0;32m----> 2\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_mean(q_values)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1075\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# Accept NumPy and scalar inputs by converting to Tensors.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_list\n\u001b[1;32m   1074\u001b[0m ):\n\u001b[0;32m-> 1075\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_convert_numpy_or_python_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m     input_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Handle `mask` propagation from previous layer to current layer. Masks\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# can be propagated explicitly via the `mask` argument, or implicitly\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;66;03m# via setting the `_keras_mask` attribute on the inputs to a Layer.\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;66;03m# Masks passed explicitly take priority.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/keras/src/engine/base_layer.py:3755\u001b[0m, in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_numpy_or_python_types\u001b[39m(x):\n\u001b[1;32m   3754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m-> 3755\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:160\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     98\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m ):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:168\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    323\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 324\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    274\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 275\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    284\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/box2d-KhiuN-9Y/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:86\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[1;32m     85\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m   value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(EPISODES):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    timestep = 0\n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        # function to override printlines from previous loop iteration \n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episodes: {progress(ep+1, EPISODES)}\")\n",
    "        print(f\"Timestep: {progress(timestep+1, 200)}, Episode reward = {episode_reward}\")\n",
    "        #Select an action\n",
    "        action = actor.model.predict(state.reshape(1, -1), verbose=0)[0]\n",
    "        \n",
    "        # Add noise to action\n",
    "        noise = ou_noise + NOISE_STDDEV * np.random.randn(action_dim)\n",
    "        action = np.clip(action + noise, -action_bound, action_bound)\n",
    "        \n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Save in the buffer replay\n",
    "        buffer.add_record(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if len(buffer.buffer) >= MINIBATCH_SIZE:\n",
    "            states, actions, rewards, next_states, dones = buffer.sample_batch(MINIBATCH_SIZE)\n",
    "\n",
    "            target_q = target_critic.model([next_states, target_actor.model.predict(next_states, verbose=0)])\n",
    "            targets = rewards + GAMMA * target_q * (1 - dones)\n",
    "\n",
    "            # Train critic\n",
    "            with tf.GradientTape() as tape:\n",
    "                critic_q = critic.model([states, actions])\n",
    "                critic_loss = tf.reduce_mean((targets - critic_q) ** 2)\n",
    "            critic_grad = tape.gradient(critic_loss, critic.model.trainable_variables)\n",
    "            critic.model.optimizer.apply_gradients(zip(critic_grad, critic.model.trainable_variables))\n",
    "\n",
    "            # Train actor\n",
    "            with tf.GradientTape() as tape:\n",
    "                new_actions = actor.model(states)\n",
    "                actor_loss = get_actor_loss(critic, states, new_actions)\n",
    "            actor_grad = tape.gradient(actor_loss, actor.model.trainable_variables)\n",
    "            actor.model.optimizer.apply_gradients(zip(actor_grad, actor.model.trainable_variables))\n",
    "\n",
    "            # Update target networks\n",
    "            update_target_weights(actor.model, target_actor.model)\n",
    "            update_target_weights(critic.model, target_critic.model)\n",
    "\n",
    "            # Decay the noise parameters at the end of the episode\n",
    "            if done:\n",
    "                NOISE_STDDEV *= NOISE_DECAY\n",
    "            timestep += 1\n",
    "\n",
    "        # Saving the episode reward\n",
    "        total_rewards += [episode_reward]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ccba70-ee91-4c9d-bb43-43702bff85a1",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "### create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fb556-2a26-469f-9e0e-71f3531c563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd027d-120a-47d8-9c74-75047e6c9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "done = False\n",
    "timestep = 0\n",
    "episode_reward = 0\n",
    "screen_list = []\n",
    "while not done:\n",
    "    # function to override printlines from previous loop iteration \n",
    "    clear_output(wait=True)\n",
    "    print(f\"Timestep: {progress(timestep+1, 200)}, Episode reward = {episode_reward}\")\n",
    "    #Select an action\n",
    "    action = actor.model.predict(state.reshape(1, -1), verbose=0)[0]\n",
    "\n",
    "    # Printing env render (rgb_array)\n",
    "    screen = env.render()\n",
    "    # Add title to the screen\n",
    "    screen = cv2.putText(\n",
    "        np.array(screen),\n",
    "        f\"Timestep=[{timestep +1}]\",\n",
    "        (25, 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 0, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "    screen_list.append(screen)\n",
    "    \n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    timestep += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dc5ad-0a3d-4f1c-beb4-e9a728b96705",
   "metadata": {},
   "source": [
    "### Save gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70de918-2773-4ad5-9c07-fe6f11349bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"./img/{ENV_NAME}.gif\"\n",
    "save_gif(screen_list, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47974b5f-a2fc-43a4-99f8-686ed3f0d3dc",
   "metadata": {},
   "source": [
    "### Embed the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efad97-1ab9-4c00-aad1-6c1a870a5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = open(path, 'rb').read()\n",
    "b64_video = base64.b64encode(video)\n",
    "video_tag = '<img src=\"data:image/gif;base64,{0}\">'.format(b64_video.decode())\n",
    "\n",
    "display(HTML(video_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06248c7-1854-4f83-b4fd-8e3382737fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
